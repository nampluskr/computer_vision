ì•„ë˜ëŠ” **CIFAR-10(32Ã—32)** ì´ë¯¸ì§€ì— *ìµœì í™”ëœ* **Generator / Discriminator** êµ¬ì¡°ì…ë‹ˆë‹¤.
ê¸°ì¡´ DCGAN ìŠ¤íƒ€ì¼ë³´ë‹¤ í›¨ì”¬ ì•ˆì •ì ì´ê³  ì„±ëŠ¥ì´ ì˜ ë‚˜ì˜¤ëŠ”, **ìµœì‹  GAN ì—°êµ¬ ê²½í–¥(ResBlock, SpectralNorm, Hinge Loss ëŒ€ì‘)**ì„ ë°˜ì˜í–ˆìŠµë‹ˆë‹¤.

> âœ” CIFAR-10 í•´ìƒë„(32Ã—32) ìµœì í™”
> âœ” ê¸°ì¡´ DCGANë³´ë‹¤ **ë” ì•ˆì •ì , ë” ì¢‹ì€ FID/IS**
> âœ” **Residual Block ê¸°ë°˜**
> âœ” **SpectralNorm Discriminator + PixelNorm Generator**
> âœ” WGAN-GP / Hinge Loss / Vanilla GAN ëª¨ë‘ í˜¸í™˜

---

# ğŸ¯ CIFAR-10 Generator / Discriminator ìµœì í™” ì›ì¹™

### Generator(G)

| í•­ëª©                         | ì´ìœ                         |
| -------------------------- | ------------------------- |
| **Residual Upsampling**    | DCGANë³´ë‹¤ í•™ìŠµ ì•ˆì •ì„± ì¦ê°€         |
| **ReLU / LeakyReLU í˜¼í•©**    | í‘œì •/ë°°ê²½ì— ë‹¤ì–‘ì„± ì¦ê°€             |
| **PixelNorm**              | ì‘ì€ í•´ìƒë„ì—ì„œ mode collapse ë°©ì§€ |
| **No Dropout**             | ìƒì„±ìì—ì„œëŠ” ì •ê·œí™”ê°€ ì˜¤íˆë ¤ í•™ìŠµì„ ë°©í•´    |
| **ConvTranspose + ì—…ìƒ˜í”Œ** ì¡°í•© | DCGAN-style aliasing ì™„í™”   |

---

### Discriminator(D)

| í•­ëª©                            | ì´ìœ                                |
| ----------------------------- | -------------------------------- |
| **SpectralNorm**              | Lipschitz ì¡°ê±´ ë³´ì¥ â†’ WGAN-GP ìˆ˜ì¤€ ì•ˆì •ì„± |
| **Residual Downsampling**     | ê³ ì£¼íŒŒ texture êµ¬ë¶„ ëŠ¥ë ¥ í–¥ìƒ             |
| **BatchNorm ì œê±°**              | Dì—ì„œ BNì€ í•™ìŠµ ë¶ˆì•ˆì • ì›ì¸                |
| **Hinge Loss / WGAN Loss í˜¸í™˜** | GAN training ì•ˆì •ì„± ì¦ê°€              |

---

# â­ ìµœì í™”ëœ CIFAR-10 Generator / Discriminator

(32Ã—32 ì´ë¯¸ì§€ ì „ìš©)

---

# ğŸ”¥ CIFAR-10 Generator (ìµœì í™” ë²„ì „)

í•´ìƒë„ íë¦„:

```
z â†’ 4Ã—4 â†’ 8Ã—8 â†’ 16Ã—16 â†’ 32Ã—32
```

```python
import torch
import torch.nn as nn


class PixelNorm(nn.Module):
    def forward(self, x):
        return x / torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + 1e-8)


class ResBlockUp(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()

        self.upsample = nn.Upsample(scale_factor=2, mode="nearest")

        self.conv1 = nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, 1, 1),
            nn.LeakyReLU(0.2, inplace=True),
            PixelNorm()
        )
        self.conv2 = nn.Sequential(
            nn.Conv2d(out_ch, out_ch, 3, 1, 1),
            nn.LeakyReLU(0.2, inplace=True),
            PixelNorm()
        )

        self.skip = nn.Conv2d(in_ch, out_ch, 1, 1, 0)

    def forward(self, x):
        skip = self.skip(self.upsample(x))
        x = self.conv1(self.upsample(x))
        x = self.conv2(x)
        return x + skip


class CIFAR10_Generator(nn.Module):
    """
    CIFAR10(32Ã—32) ìµœì í™” Generator
    - ResBlock ì—…ìƒ˜í”Œë§
    - PixelNorm
    """
    def __init__(self, z_dim=128, base_ch=256, out_channels=3):
        super().__init__()

        # z â†’ 4Ã—4
        self.initial = nn.Sequential(
            nn.ConvTranspose2d(z_dim, base_ch, 4, 1, 0),
            nn.LeakyReLU(0.2, inplace=True),
            PixelNorm(),
        )

        # 4â†’8 â†’16 â†’32
        self.up1 = ResBlockUp(base_ch, base_ch // 2)      # 256 â†’ 128
        self.up2 = ResBlockUp(base_ch // 2, base_ch // 4) # 128 â†’ 64
        self.up3 = ResBlockUp(base_ch // 4, base_ch // 8) # 64 â†’ 32

        self.to_rgb = nn.Conv2d(base_ch // 8, out_channels, 1)

    def forward(self, z):
        x = self.initial(z.view(z.size(0), -1, 1, 1))
        x = self.up1(x)
        x = self.up2(x)
        x = self.up3(x)
        return torch.tanh(self.to_rgb(x))
```

---

# ğŸ”¥ CIFAR-10 Discriminator (ìµœì í™” ë²„ì „)

í•´ìƒë„ íë¦„:

```
32Ã—32 â†’ 16Ã—16 â†’ 8Ã—8 â†’ 4Ã—4 â†’ scalar
```

* SpectralNorm ì ìš©
* Residual Downsampling
* BatchNorm ì—†ìŒ â†’ GAN í•™ìŠµ ì•ˆì •ì„± ì¦ê°€

```python
from torch.nn.utils import spectral_norm


class ResBlockDown(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()

        self.conv1 = nn.Sequential(
            spectral_norm(nn.Conv2d(in_ch, out_ch, 3, 1, 1)),
            nn.LeakyReLU(0.2, inplace=True)
        )
        self.conv2 = nn.Sequential(
            spectral_norm(nn.Conv2d(out_ch, out_ch, 3, 1, 1)),
            nn.LeakyReLU(0.2, inplace=True)
        )

        self.down = nn.AvgPool2d(2)

        self.skip = spectral_norm(nn.Conv2d(in_ch, out_ch, 1, 2, 0))

    def forward(self, x):
        skip = self.skip(x)
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.down(x)
        return x + skip


class CIFAR10_Discriminator(nn.Module):
    """
    CIFAR10(32Ã—32) ìµœì í™” Discriminator
    - SpectralNorm
    - Res Downsample
    """
    def __init__(self, base_ch=64, in_channels=3, use_sigmoid=False):
        super().__init__()
        self.use_sigmoid = use_sigmoid

        # from rgb
        self.from_rgb = spectral_norm(nn.Conv2d(in_channels, base_ch, 1))

        # 32â†’16â†’8â†’4
        self.block1 = ResBlockDown(base_ch, base_ch * 2)
        self.block2 = ResBlockDown(base_ch * 2, base_ch * 4)
        self.block3 = ResBlockDown(base_ch * 4, base_ch * 4)

        self.final = nn.Sequential(
            spectral_norm(nn.Conv2d(base_ch * 4, base_ch * 8, 3, 1, 1)),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Flatten(),
            spectral_norm(nn.Linear(base_ch * 8 * 4 * 4, 1))
        )

    def forward(self, x):
        x = self.from_rgb(x)
        x = self.block1(x)
        x = self.block2(x)
        x = self.block3(x)
        x = self.final(x)
        return torch.sigmoid(x) if self.use_sigmoid else x
```

---

# ğŸ“Œ ì´ êµ¬ì¡°ê°€ DCGANë³´ë‹¤ í›¨ì”¬ ë” ì¢‹ì€ ì´ìœ 

| ê°œì„  ìš”ì†Œ                            | ì„¤ëª…                            |
| -------------------------------- | ----------------------------- |
| Residual Upsampling/Downsampling | ê²½ì‚¬íë¦„ ì•ˆì • â†’ í° ê°œì„  íš¨ê³¼             |
| PixelNorm (G)                    | ì‘ì€ í•´ìƒë„ì—ì„œ Gì˜ mode collapse ë°©ì§€  |
| SpectralNorm (D)                 | Lipschitz ë³´ì¥ â†’ í­ë°œ/ë¶•ê´´ ë°©ì§€       |
| BatchNorm ì œê±°(D)                  | Dì˜ batch dependency ì œê±° â†’ ë” ê²¬ê³  |
| ReLU/LeakyReLU ì¡°í•©                | CIFAR10ê°™ì€ natural imageì— ìµœì    |

ì‹¤ì œ ì—°êµ¬ì—ì„œë„ CIFAR10ì—ì„œ
**ResNet ê¸°ë°˜ GANì´ DCGANë³´ë‹¤ í›¨ì”¬ ì¢‹ì€ ì„±ëŠ¥(FID/IS)**ì„ ëƒ…ë‹ˆë‹¤.

---

# ğŸ‰ ì™„ì„±: CIFAR-10 ìµœì í™” Generator & Discriminator

ì´ì œ CIFAR10 í•™ìŠµì—ì„œ
**GAN / WGAN-GP / HingeGAN / CGAN / CWGAN-GP**
ëª¨ë‘ ìœ„ ëª¨ë¸ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

---

# ğŸ“Œ ë‹¤ìŒ ë‹¨ê³„ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤

ì•„ë˜ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”:

### ğŸ”¥ A) ìœ„ CIFAR-10 ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” **WGAN-GP í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸**

### ğŸ”¥ B) CIFAR-10 **HingeGAN** ì „ì²´ ì½”ë“œ

### ğŸ”¥ C) CIFAR-10 **Conditional WGAN-GP (CWGAN-GP)** ë²„ì „

### ğŸ”¥ D) CIFAR-10 GAN ì„±ëŠ¥ ë¹„êµ ì‹¤í—˜ ì½”ë“œ(GAN/WGAN/CGAN/CWGAN-GP)

### ğŸ”¥ E) CIFAR-10ìš© StyleGAN-Lite êµ¬ì¡° ìƒì„±

ì›í•˜ì‹œëŠ” í•­ëª©ì„ ì•Œë ¤ì£¼ì„¸ìš”!
