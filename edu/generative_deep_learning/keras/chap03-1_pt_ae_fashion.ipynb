{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b0fc92",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'/home/nampl/anaconda3/envs/tensorflow_env/lib/python3.10/site-packages/typing_extensions.py'에서 'TypeAliasType'을(를) 가져올 수 없기 때문에 kernel을 시작하지 못했습니다.\n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>여기</a>를 클릭합니다."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_strict_conv_algorithm_picker=false'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "        # 추가: GPU 메모리 제한 (선택사항)\n",
    "        # tf.config.set_logical_device_configuration(\n",
    "        #     gpus[0],\n",
    "        #     [tf.config.LogicalDeviceConfiguration(memory_limit=4096)])\n",
    "        \n",
    "        print(f\"GPU 설정 완료: {len(gpus)}개\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        \n",
    "print(f\"현재 정책: {tf.keras.mixed_precision.global_policy()}\")\n",
    "print(f\"GPU 장치: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bceb44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import gc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, utils, layers, models, optimizers\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37290dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     for gpu in gpus:\n",
    "#         tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd4f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fashion_mnist(root_dir):\n",
    "    data_dir = root_dir\n",
    "    if not os.path.exists(data_dir):\n",
    "        raise FileNotFoundError(f\"Fashion MNIST Not Found!: {data_dir}\")\n",
    "\n",
    "    train_images_path = os.path.join(data_dir, 'train-images-idx3-ubyte.gz')\n",
    "    train_labels_path = os.path.join(data_dir, 'train-labels-idx1-ubyte.gz')\n",
    "    test_images_path = os.path.join(data_dir, 't10k-images-idx3-ubyte.gz')\n",
    "    test_labels_path = os.path.join(data_dir, 't10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "    with gzip.open(train_images_path, 'rb') as f:\n",
    "        x_train = np.frombuffer(f.read(), dtype=np.uint8, offset=16)\n",
    "        x_train = x_train.reshape(-1, 28, 28)\n",
    "\n",
    "    with gzip.open(train_labels_path, 'rb') as f:\n",
    "        y_train = np.frombuffer(f.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(test_images_path, 'rb') as f:\n",
    "        x_test = np.frombuffer(f.read(), dtype=np.uint8, offset=16)\n",
    "        x_test = x_test.reshape(-1, 28, 28)\n",
    "\n",
    "    with gzip.open(test_labels_path, 'rb') as f:\n",
    "        y_test = np.frombuffer(f.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def preprocess(imgs):\n",
    "    imgs = imgs.astype(\"float32\") / 255.0\n",
    "    imgs = np.pad(imgs, ((0, 0), (2, 2), (2, 2)), constant_values=0.0)\n",
    "    imgs = np.expand_dims(imgs, -1)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c5bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32\n",
    "CHANNELS = 1\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 1000\n",
    "VALIDATION_SPLIT = 0.2\n",
    "EMBEDDING_DIM = 2\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0ba1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/mnt/d/datasets/fashion_mnist'\n",
    "(x_train,y_train), (x_test,y_test) = load_fashion_mnist(root_dir)\n",
    "\n",
    "x_train = preprocess(x_train)\n",
    "x_test = preprocess(x_test)\n",
    "\n",
    "print(f\"train images: {type(x_train)} {x_train.shape}, dtype={x_train.dtype}, min={x_train.min()}, max={x_train.max()}\")\n",
    "print(f\"train labels: {type(y_train)} {y_train.shape}, dtype={y_train.dtype}, min={y_train.min()}, max={y_train.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd458049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_input = layers.Input(shape=(32, 32, 1), name = \"encoder_input\")\n",
    "x = layers.Conv2D(32, (3, 3), strides = 2, activation = 'relu', padding=\"same\")(encoder_input)\n",
    "x = layers.Conv2D(64, (3, 3), strides = 2, activation = 'relu', padding=\"same\")(x)\n",
    "x = layers.Conv2D(128, (3, 3), strides = 2, activation = 'relu', padding=\"same\")(x)\n",
    "shape_before_flattening = K.int_shape(x)[1:]\n",
    "x = layers.Flatten()(x)\n",
    "encoder_output = layers.Dense(2, name=\"encoder_output\")(x)\n",
    "encoder = models.Model(encoder_input, encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bf7d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "decoder_input = layers.Input(shape=(2,), name=\"decoder_input\")\n",
    "x = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "x = layers.Reshape(shape_before_flattening)(x)\n",
    "x = layers.Conv2DTranspose(128, (3, 3), strides=2, activation = 'relu', padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(64, (3, 3), strides=2, activation = 'relu', padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation = 'relu', padding=\"same\")(x)\n",
    "decoder_output = layers.Conv2D(1, (3, 3), strides = 1, activation=\"sigmoid\",\n",
    "    padding=\"same\", name=\"decoder_output\")(x)\n",
    "decoder = models.Model(decoder_input, decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa3a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder\n",
    "autoencoder = models.Model(encoder_input, decoder(encoder_output))\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "autoencoder.fit(x_train, x_train, epochs=5, batch_size=100, shuffle=True, \n",
    "    validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eafa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.clear_session()\n",
    "# gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
