{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b73f8932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from discriminators import Discriminator32\n",
    "from generators import Generator32\n",
    "from gan import GAN\n",
    "\n",
    "from cifar10 import CIFAR10, get_train_loader\n",
    "from utils import set_seed\n",
    "from train import train_gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6a1468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BATCH_SIZE = 128\n",
    "NUM_SAMPLES = 100\n",
    "\n",
    "LATENT_DIM = 100\n",
    "IN_CHANNELS = 3\n",
    "OUT_CHANNELS = 3\n",
    "BASE = 64\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "TOTAL_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d841618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/5] d_loss:0.426, real_loss:0.228, fake_loss:0.198, g_loss:4.694                                                  \n",
      "[  2/5] d_loss:0.443, real_loss:0.236, fake_loss:0.207, g_loss:3.981                                                   \n",
      "[  3/5] d_loss:0.506, real_loss:0.261, fake_loss:0.245, g_loss:3.110                                                  \n",
      "[  4/5] d_loss:0.450, real_loss:0.223, fake_loss:0.227, g_loss:3.104                                                  \n",
      "[  5/5] d_loss:0.609, real_loss:0.310, fake_loss:0.299, g_loss:2.849                                                   \n",
      ">> ./outputs/cifar10_gan-bce_epoch005.png is saved.\n",
      "\n",
      "[  1/5] d_loss:0.688, real_loss:0.345, fake_loss:0.343, g_loss:2.219                                                  \n",
      "[  2/5] d_loss:0.752, real_loss:0.380, fake_loss:0.372, g_loss:2.266                                                  \n",
      "[  3/5] d_loss:0.724, real_loss:0.360, fake_loss:0.363, g_loss:2.371                                                  \n",
      "[  4/5] d_loss:0.721, real_loss:0.362, fake_loss:0.359, g_loss:2.220                                                  \n",
      "[  5/5] d_loss:0.748, real_loss:0.370, fake_loss:0.378, g_loss:2.211                                                  \n",
      ">> ./outputs/cifar10_gan-bce_epoch010.png is saved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LOSS_TYPE = \"bce\"\n",
    "FILENAME = f\"cifar10_gan-{LOSS_TYPE}\"\n",
    "\n",
    "set_seed(SEED)\n",
    "dataset = CIFAR10(root_dir=\"/mnt/d/datasets/cifar10\", split=\"train\",\n",
    "                  transform=T.Compose([T.ToTensor(), T.Normalize(mean=[0.5]*3, std=[0.5]*3)]))\n",
    "train_loader = get_train_loader(dataset, batch_size=BATCH_SIZE)\n",
    "noises = np.random.normal(size=(NUM_SAMPLES, LATENT_DIM, 1, 1))\n",
    "\n",
    "discriminator = Discriminator32(in_channels=IN_CHANNELS, base=BASE)\n",
    "generator = Generator32(latent_dim=LATENT_DIM, out_channels=OUT_CHANNELS, base=BASE)\n",
    "gan = GAN(discriminator, generator, loss_type=LOSS_TYPE)\n",
    "history = train_gan(gan, train_loader, num_epochs=NUM_EPOCHS, total_epochs=TOTAL_EPOCHS, \n",
    "                    noises=noises, filename=FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "437c7465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/5] d_loss:0.721, real_loss:0.169, fake_loss:0.552, g_loss:2.791                                                  \n",
      "[  2/5] d_loss:0.231, real_loss:0.135, fake_loss:0.096, g_loss:0.794                                                  \n",
      "[  3/5] d_loss:0.305, real_loss:0.168, fake_loss:0.137, g_loss:0.734                                                  \n",
      "[  4/5] d_loss:0.288, real_loss:0.156, fake_loss:0.132, g_loss:0.812                                                  \n",
      "[  5/5] d_loss:0.340, real_loss:0.177, fake_loss:0.164, g_loss:0.768                                                  \n",
      ">> ./outputs/cifar10_gan-mse_epoch005.png is saved.\n",
      "\n",
      "[  1/5] d_loss:0.324, real_loss:0.169, fake_loss:0.155, g_loss:0.775                                                  \n",
      "[  2/5] d_loss:0.342, real_loss:0.174, fake_loss:0.168, g_loss:0.728                                                  \n",
      "[  3/5] d_loss:0.285, real_loss:0.146, fake_loss:0.138, g_loss:0.726                                                  \n",
      "[  4/5] d_loss:0.338, real_loss:0.172, fake_loss:0.166, g_loss:0.674                                                  \n",
      "[  5/5] d_loss:0.359, real_loss:0.181, fake_loss:0.178, g_loss:0.675                                                  \n",
      ">> ./outputs/cifar10_gan-mse_epoch010.png is saved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LOSS_TYPE = \"mse\"\n",
    "FILENAME = f\"cifar10_gan-{LOSS_TYPE}\"\n",
    "\n",
    "set_seed(SEED)\n",
    "dataset = CIFAR10(root_dir=\"/mnt/d/datasets/cifar10\", split=\"train\",\n",
    "                  transform=T.Compose([T.ToTensor(), T.Normalize(mean=[0.5]*3, std=[0.5]*3)]))\n",
    "train_loader = get_train_loader(dataset, batch_size=BATCH_SIZE)\n",
    "noises = np.random.normal(size=(NUM_SAMPLES, LATENT_DIM, 1, 1))\n",
    "\n",
    "discriminator = Discriminator32(in_channels=IN_CHANNELS, base=BASE)\n",
    "generator = Generator32(latent_dim=LATENT_DIM, out_channels=OUT_CHANNELS, base=BASE)\n",
    "gan = GAN(discriminator, generator, loss_type=LOSS_TYPE)\n",
    "history = train_gan(gan, train_loader, num_epochs=NUM_EPOCHS, total_epochs=TOTAL_EPOCHS, \n",
    "                    noises=noises, filename=FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab61613b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/5] d_loss:0.556, real_loss:0.308, fake_loss:0.247, g_loss:3.355                                                  \n",
      "[  2/5] d_loss:0.464, real_loss:0.251, fake_loss:0.213, g_loss:2.418                                                  \n",
      "[  3/5] d_loss:0.565, real_loss:0.294, fake_loss:0.271, g_loss:1.833                                                  \n",
      "[  4/5] d_loss:0.444, real_loss:0.227, fake_loss:0.218, g_loss:1.848                                                  \n",
      "[  5/5] d_loss:0.742, real_loss:0.377, fake_loss:0.365, g_loss:1.624                                                  \n",
      ">> ./outputs/cifar10_gan-hinge_epoch005.png is saved.\n",
      "\n",
      "[  1/5] d_loss:0.801, real_loss:0.398, fake_loss:0.403, g_loss:1.420                                                  \n",
      "[  2/5] d_loss:0.812, real_loss:0.403, fake_loss:0.408, g_loss:1.423                                                  \n",
      "[  3/5] d_loss:0.824, real_loss:0.415, fake_loss:0.409, g_loss:1.390                                                   \n",
      "[  4/5] d_loss:0.811, real_loss:0.403, fake_loss:0.408, g_loss:1.359                                                  \n",
      "[  5/5] d_loss:0.784, real_loss:0.384, fake_loss:0.400, g_loss:1.333                                                  \n",
      ">> ./outputs/cifar10_gan-hinge_epoch010.png is saved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LOSS_TYPE = \"hinge\"\n",
    "FILENAME = f\"cifar10_gan-{LOSS_TYPE}\"\n",
    "\n",
    "set_seed(SEED)\n",
    "dataset = CIFAR10(root_dir=\"/mnt/d/datasets/cifar10\", split=\"train\",\n",
    "                  transform=T.Compose([T.ToTensor(), T.Normalize(mean=[0.5]*3, std=[0.5]*3)]))\n",
    "train_loader = get_train_loader(dataset, batch_size=BATCH_SIZE)\n",
    "noises = np.random.normal(size=(NUM_SAMPLES, LATENT_DIM, 1, 1))\n",
    "\n",
    "discriminator = Discriminator32(in_channels=IN_CHANNELS, base=BASE)\n",
    "generator = Generator32(latent_dim=LATENT_DIM, out_channels=OUT_CHANNELS, base=BASE)\n",
    "gan = GAN(discriminator, generator, loss_type=LOSS_TYPE)\n",
    "history = train_gan(gan, train_loader, num_epochs=NUM_EPOCHS, total_epochs=TOTAL_EPOCHS, \n",
    "                    noises=noises, filename=FILENAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
