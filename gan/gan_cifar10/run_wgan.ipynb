{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b73f8932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from discriminators import Discriminator32\n",
    "from generators import Generator32\n",
    "from gan import WGAN\n",
    "\n",
    "from cifar10 import CIFAR10, get_train_loader\n",
    "from utils import set_seed\n",
    "from train import train_gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "193f3a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "def reset_environment(seed=42):\n",
    "    set_seed(seed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\">> Environment reset with seed={seed}\")\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**2\n",
    "        reserved = torch.cuda.memory_reserved() / 1024**2\n",
    "        print(f\"   GPU memory: {allocated:.2f} MB allocated, {reserved:.2f} MB reserved\")\n",
    "\n",
    "\n",
    "def cleanup_experiment(gan=None, train_loader=None):\n",
    "    if gan is not None:\n",
    "        if hasattr(gan, 'c_optimizer'):\n",
    "            del gan.c_optimizer\n",
    "        if hasattr(gan, 'g_optimizer'):\n",
    "            del gan.g_optimizer\n",
    "        \n",
    "        if hasattr(gan, 'critic'):\n",
    "            del gan.critic\n",
    "        if hasattr(gan, 'generator'):\n",
    "            del gan.generator\n",
    "        \n",
    "        del gan\n",
    "    \n",
    "    if train_loader is not None:\n",
    "        del train_loader\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\">> Cleanup completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a1468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BATCH_SIZE = 128\n",
    "NUM_SAMPLES = 100\n",
    "\n",
    "LATENT_DIM = 100\n",
    "IN_CHANNELS = 3\n",
    "OUT_CHANNELS = 3\n",
    "BASE = 64\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "TOTAL_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c04724b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/5] d_loss:-15.399, real_loss:-2.541, fake_loss:-12.858, g_loss:13.173, gp:0.273                                                  \n",
      "[  2/5] d_loss:-7.456, real_loss:-2.606, fake_loss:-4.850, g_loss:5.091, gp:0.168                                                  \n",
      "                                                                                                                                   \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m generator = Generator32(latent_dim=LATENT_DIM, out_channels=OUT_CHANNELS, base=BASE)\n\u001b[32m     12\u001b[39m gan = WGAN(discriminator, generator, use_gp=\u001b[38;5;28;01mTrue\u001b[39;00m, one_sided=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m history = \u001b[43mtrain_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTOTAL_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mnoises\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnoises\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFILENAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m cleanup_experiment(gan, train_loader)\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m discriminator, generator, dataset, noises\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/github/computer_vision/gan/gan_cifar10/train.py:17\u001b[39m, in \u001b[36mtrain_gan\u001b[39m\u001b[34m(gan, train_loader, num_epochs, total_epochs, noises, labels, filename)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_epochs // num_epochs):\n\u001b[32m     16\u001b[39m     epoch += num_epochs\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     epoch_history = \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     update_history(history, epoch_history)\n\u001b[32m     20\u001b[39m     images = create_images(gan.generator, noises, labels=labels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/github/computer_vision/gan/gan_cifar10/train.py:72\u001b[39m, in \u001b[36mfit\u001b[39m\u001b[34m(model, train_loader, num_epochs, valid_loader)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, num_epochs + \u001b[32m1\u001b[39m):\n\u001b[32m     71\u001b[39m     epoch_info = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m3d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     train_results = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m     train_info = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m train_results.items()])\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m train_results.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/github/computer_vision/gan/gan_cifar10/train.py:36\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, dataloader)\u001b[39m\n\u001b[32m     33\u001b[39m batch_size = batch[\u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m].shape[\u001b[32m0\u001b[39m]\n\u001b[32m     34\u001b[39m total += batch_size\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m outputs.items():\n\u001b[32m     38\u001b[39m     results.setdefault(name, \u001b[32m0.0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/github/computer_vision/gan/gan_cifar10/gan.py:170\u001b[39m, in \u001b[36mWGAN.train_step\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.d_steps):\n\u001b[32m    169\u001b[39m     real_logits = \u001b[38;5;28mself\u001b[39m.critic(real_images)\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     noises = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m     fake_images = \u001b[38;5;28mself\u001b[39m.generator(noises).detach()\n\u001b[32m    172\u001b[39m     fake_logits = \u001b[38;5;28mself\u001b[39m.critic(fake_images)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "set_seed(SEED)\n",
    "LOSS_TYPE = \"gp_one-sided\"\n",
    "FILENAME = f\"cifar10_wgan-{LOSS_TYPE}\"\n",
    "\n",
    "dataset = CIFAR10(root_dir=\"/mnt/d/datasets/cifar10\", split=\"train\",\n",
    "                  transform=T.Compose([T.ToTensor(), T.Normalize(mean=[0.5]*3, std=[0.5]*3)]))\n",
    "train_loader = get_train_loader(dataset, batch_size=BATCH_SIZE)\n",
    "noises = np.random.normal(size=(NUM_SAMPLES, LATENT_DIM, 1, 1)) \n",
    "\n",
    "discriminator = Discriminator32(in_channels=IN_CHANNELS, base=BASE)\n",
    "generator = Generator32(latent_dim=LATENT_DIM, out_channels=OUT_CHANNELS, base=BASE)\n",
    "gan = WGAN(discriminator, generator, use_gp=True, one_sided=True)\n",
    "history = train_gan(gan, train_loader, num_epochs=NUM_EPOCHS, total_epochs=TOTAL_EPOCHS, \n",
    "                    noises=noises, filename=FILENAME)\n",
    "\n",
    "cleanup_experiment(gan, train_loader)\n",
    "del discriminator, generator, dataset, noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93d89b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Environment reset with seed=42\n",
      "   GPU memory: 0.00 MB allocated, 0.00 MB reserved\n",
      "[  1/5] d_loss:-0.501, real_loss:-0.255, fake_loss:-0.245, g_loss:0.248                                                  \n",
      "[  2/5] d_loss:-0.464, real_loss:-0.237, fake_loss:-0.227, g_loss:0.230                                                  \n",
      "[  3/5] d_loss:-0.347, real_loss:-0.179, fake_loss:-0.168, g_loss:0.171                                                  \n",
      "[  4/5] d_loss:-0.308, real_loss:-0.158, fake_loss:-0.150, g_loss:0.152                                                  \n",
      "[  5/5] d_loss:-0.281, real_loss:-0.144, fake_loss:-0.137, g_loss:0.136                                                  \n",
      ">> ./outputs/cifar10_wgan-default_epoch005.png is saved.\n",
      "\n",
      "[  1/5] d_loss:-0.268, real_loss:-0.138, fake_loss:-0.130, g_loss:0.130                                                  \n",
      "[  2/5] d_loss:-0.263, real_loss:-0.134, fake_loss:-0.129, g_loss:0.126                                                  \n",
      "[  3/5] d_loss:-0.244, real_loss:-0.124, fake_loss:-0.121, g_loss:0.117                                                  \n",
      "[  4/5] d_loss:-0.226, real_loss:-0.115, fake_loss:-0.111, g_loss:0.109                                                  \n",
      "[  5/5] d_loss:-0.214, real_loss:-0.110, fake_loss:-0.104, g_loss:0.103                                                  \n",
      ">> ./outputs/cifar10_wgan-default_epoch010.png is saved.\n",
      "\n",
      ">> Cleanup completed\n"
     ]
    }
   ],
   "source": [
    "reset_environment(SEED)\n",
    "LOSS_TYPE = \"default\"\n",
    "FILENAME = f\"cifar10_wgan-{LOSS_TYPE}\"\n",
    "\n",
    "dataset = CIFAR10(root_dir=\"/mnt/d/datasets/cifar10\", split=\"train\",\n",
    "                  transform=T.Compose([T.ToTensor(), T.Normalize(mean=[0.5]*3, std=[0.5]*3)]))\n",
    "train_loader = get_train_loader(dataset, batch_size=BATCH_SIZE)\n",
    "noises = np.random.normal(size=(NUM_SAMPLES, LATENT_DIM, 1, 1)) \n",
    "\n",
    "discriminator = Discriminator32(in_channels=IN_CHANNELS, base=BASE)\n",
    "generator = Generator32(latent_dim=LATENT_DIM, out_channels=OUT_CHANNELS, base=BASE)\n",
    "gan = WGAN(discriminator, generator, use_gp=False, one_sided=False)\n",
    "history = train_gan(gan, train_loader, num_epochs=NUM_EPOCHS, total_epochs=TOTAL_EPOCHS, \n",
    "                    noises=noises, filename=FILENAME)\n",
    "\n",
    "cleanup_experiment(gan, train_loader)\n",
    "del discriminator, generator, dataset, noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96c9a271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Environment reset with seed=42\n",
      "   GPU memory: 0.00 MB allocated, 0.00 MB reserved\n",
      "[  1/5] d_loss:-15.457, real_loss:-2.429, fake_loss:-13.028, g_loss:13.346, gp:0.270                                                  \n",
      "[  2/5] d_loss:-7.344, real_loss:-2.331, fake_loss:-5.012, g_loss:5.149, gp:0.178                                                  \n",
      "[  3/5] d_loss:-5.385, real_loss:-0.324, fake_loss:-5.061, g_loss:5.085, gp:0.083                                                  \n",
      "[  4/5] d_loss:-50.365, real_loss:-45.089, fake_loss:-5.276, g_loss:5.374, gp:1.952                                                  \n",
      "[  5/5] d_loss:-5.712, real_loss:0.597, fake_loss:-6.309, g_loss:6.322, gp:0.217                                                  \n",
      ">> ./outputs/cifar10_wgan-gp_epoch005.png is saved.\n",
      "\n",
      "[  1/5] d_loss:-6.306, real_loss:-3.400, fake_loss:-2.906, g_loss:2.856, gp:0.265                                                  \n",
      "[  2/5] d_loss:-6.822, real_loss:-4.049, fake_loss:-2.772, g_loss:2.787, gp:0.372                                                  \n",
      "[  3/5] d_loss:-6.473, real_loss:-2.557, fake_loss:-3.916, g_loss:3.897, gp:0.440                                                  \n",
      "[  4/5] d_loss:-6.166, real_loss:-0.886, fake_loss:-5.280, g_loss:5.377, gp:0.381                                                  \n",
      "[  5/5] d_loss:-6.260, real_loss:0.967, fake_loss:-7.227, g_loss:7.387, gp:0.343                                                  \n",
      ">> ./outputs/cifar10_wgan-gp_epoch010.png is saved.\n",
      "\n",
      ">> Cleanup completed\n"
     ]
    }
   ],
   "source": [
    "reset_environment(SEED)\n",
    "LOSS_TYPE = \"gp\"\n",
    "FILENAME = f\"cifar10_wgan-{LOSS_TYPE}\"\n",
    "\n",
    "dataset = CIFAR10(root_dir=\"/mnt/d/datasets/cifar10\", split=\"train\",\n",
    "                  transform=T.Compose([T.ToTensor(), T.Normalize(mean=[0.5]*3, std=[0.5]*3)]))\n",
    "train_loader = get_train_loader(dataset, batch_size=BATCH_SIZE)\n",
    "noises = np.random.normal(size=(NUM_SAMPLES, LATENT_DIM, 1, 1)) \n",
    "\n",
    "discriminator = Discriminator32(in_channels=IN_CHANNELS, base=BASE)\n",
    "generator = Generator32(latent_dim=LATENT_DIM, out_channels=OUT_CHANNELS, base=BASE)\n",
    "gan = WGAN(discriminator, generator, use_gp=True, one_sided=False)\n",
    "history = train_gan(gan, train_loader, num_epochs=NUM_EPOCHS, total_epochs=TOTAL_EPOCHS, \n",
    "                    noises=noises, filename=FILENAME)\n",
    "\n",
    "cleanup_experiment(gan, train_loader)\n",
    "del discriminator, generator, dataset, noises"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
